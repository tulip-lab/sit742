{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SIT742P07B-MLlib-DataType.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.5","name":"python3","language":"python"}},"cells":[{"metadata":{"id":"rF7pYIhsLtui","colab_type":"text"},"cell_type":"markdown","source":["# SIT742: Modern Data Science \n","**(Week 07: Big Data Platform (II))**\n","\n","---\n","- Materials in this module include resources collected from various open-source online repositories.\n","- You are free to use, change and distribute this package.\n","- If you found any issue/bug for this document, please submit an issue at [tulip-lab/sit742](https://github.com/tulip-lab/sit742/issues)\n","\n","Prepared by **SIT742 Teaching Team**\n","\n","---\n","\n","\n","\n","## Session 7B - Spark MLlib (1): Data Types\n","\n","\n","The purpose of this session is to demonstrate different coefficient and linear regression.\n","\n","\n","### Content\n","\n","### Part 1 Vectors\n","\n","1.1 [Dense and Sparse Vectors](#dsvec)\n","\n","1.2 [Labeled Points](#lpoints)\n","\n","\n","### Part 2 Matrix \n","\n","Local Matrix\n","Row Matrix\n","\n","\n","2.1 [Local Matrix](#lm)\n","\n","2.2 [Row Matrix](#rm)\n","\n","2.3 [Indexed Row Matrix](#irm)\n","\n","2.4 [Coordinate Matrix](#cm)\n","\n","2.5 [Block Matrix](#bm)\n","\n","### Part 3 Matrix Conversions\n","\n","3.1 [Indexed Row Matrix Conversions](#irmc)\n","\n","3.2 [Coordinate Matrix Conversions](#cmc)\n","\n","3.3 [Block Matrix Conversions](#bmc)\n"]},{"metadata":{"id":"fxE6Q1h2Ltuj","colab_type":"text"},"cell_type":"markdown","source":["---\n","## <span style=\"color:#0b486b\">1. Vectors</span>\n","\n","<a id = \"dsvec\"></a>\n","### <span style=\"color:#0b486b\">1.1 Dense and Sparse Vectors</span>\n","\n","Spark has many libraries, namely under MLlib (Machine Learning Library)! Spark allows for quick and easy scalability of practical machine learning!\n","\n","In this lab exercise, you will learn about the basic Data Types that are used in Spark MLlib. This lab will help you develop the building blocks required to continue developing knowledge in machine learning with Spark.\n","\n","Import the following libraries: <br>\n","<ul>\n","    <li> numpy as np </li>\n","    <li> scipy.sparse as sps </li>\n","    <li> Vectors from pyspark.mllib.linalg </li>\n","</ul>"]},{"metadata":{"id":"LMSzEzOPQ94_","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n","!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n","\n","import findspark\n","findspark.init() "],"execution_count":0,"outputs":[]},{"metadata":{"id":"5OKTJqzVLtuk","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import scipy.sparse as sps\n","from pyspark.mllib.linalg import Vectors\n","\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-GjbNjCnLtuo","colab_type":"text"},"cell_type":"markdown","source":["First, we will be dealing with <b>Dense Vectors</b>. There are 2 types of <b>dense vectors</b> that we can create.<br>\n","The dense vectors will be modeled having the values: <b>8.0, 312.0, -9.0, 1.3</b>"]},{"metadata":{"id":"x_t6dCTJLtuo","colab_type":"text"},"cell_type":"markdown","source":["The first <b>dense vector</b> we will create is as easy as creating a <b>numpy array</b>. <br>\n","Using the np.array function, create a <b>dense vector</b> called <b>dense_vector1</b> <br> <br>\n","Note: numpy's array function takes an array as input"]},{"metadata":{"id":"spj1u4WqLtup","colab_type":"code","colab":{}},"cell_type":"code","source":["dense_vector1 = np.array([8.0, 312.0, -9.0, 1.3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NLYlm0kHLtur","colab_type":"text"},"cell_type":"markdown","source":["Print <b>dense_vector1</b> and its <b>type</b>"]},{"metadata":{"id":"zqz2UAUyLtur","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"9a1bf3d5-c392-46cf-9b22-21987929cf07","executionInfo":{"status":"ok","timestamp":1552198953465,"user_tz":-660,"elapsed":21135,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print (dense_vector1)\n","type(dense_vector1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[  8.  312.   -9.    1.3]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"3qv14ZuFLtut","colab_type":"text"},"cell_type":"markdown","source":["The second <b>dense vector</b> is easier than the first, and is made by creating an <b>array</b>. <br>\n","Create a <b>dense vector</b> called <b>dense_vector2</b>"]},{"metadata":{"id":"NgHqVADALtut","colab_type":"code","colab":{}},"cell_type":"code","source":["dense_vector2 = [8.0, 312.0, -9.0, 1.3]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tKiEp-cvLtuv","colab_type":"text"},"cell_type":"markdown","source":["Print <b>dense_vector2</b> and its <b>type</b>"]},{"metadata":{"id":"IViOJgfeLtuw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"1ad10d5e-584b-4735-d6a3-7035024ac3b5","executionInfo":{"status":"ok","timestamp":1552198953468,"user_tz":-660,"elapsed":21136,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print (dense_vector2)\n","type (dense_vector2)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[8.0, 312.0, -9.0, 1.3]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"dTXUbxQKLtux","colab_type":"text"},"cell_type":"markdown","source":["Next, we will be dealing with <b>sparse vectors</b>. There are 2 types of <b>sparse vectors</b> we can create. <br>\n","The sparse vectors we will be creating will follow these values: <b> 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 6.5 </b>"]},{"metadata":{"id":"J_bkfTv_Ltuy","colab_type":"text"},"cell_type":"markdown","source":["First, create a <b>sparse vector</b> called <b>sparse_vector1</b> using Vector's <b>sparse</b> function. <br>\n","Inputs to Vector.sparse: <br>\n","<ul>\n","    <li>1st: Size of the sparse vector</li>\n","    <li>2nd: Indicies of array</li>\n","    <li>3rd: Values placed where the indices are</li>\n","</ul>"]},{"metadata":{"id":"xQjlxLH5Ltuz","colab_type":"code","colab":{}},"cell_type":"code","source":["sparse_vector1 = Vectors.sparse(10, [0, 3, 5, 9], [7.0, 2.0, 1.0, 6.5])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7BQwZsedLtu1","colab_type":"text"},"cell_type":"markdown","source":["Print <b>sparse_vector1</b> and its <b>type</b>"]},{"metadata":{"id":"TPcC4TWpLtu2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"d368d903-602e-40b0-f586-cf6bf17f5fa9","executionInfo":{"status":"ok","timestamp":1552198953471,"user_tz":-660,"elapsed":21137,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(sparse_vector1)\n","type(sparse_vector1)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(10,[0,3,5,9],[7.0,2.0,1.0,6.5])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["pyspark.mllib.linalg.SparseVector"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"VFPkxm3WLtu3","colab_type":"text"},"cell_type":"markdown","source":["Next we will create a <b>sparse vector</b> called <b>sparse_vector2</b> using a single-column SciPy <b>csc_matrix</b> <br> <br>\n","The inputs to sps.csc_matrix are: <br>\n","<ul>\n","    <li>1st: A tuple consisting of the three inputs:</li>\n","    <ul>\n","        <li>1st: Data Values (in a numpy array) (values placed at the specified indices)</li>\n","        <li>2nd: Indicies of the array (in a numpy array) (where the values will be placed)</li>\n","        <li>3rd: Index pointer of the array (in a numpy array)</li>\n","    </ul>\n","    <li>2nd: Shape of the array (#rows, #columns) Use 10 rows and 1 column</li>\n","    <ul>\n","        <li>shape = (\\_,\\_)</li>\n","    </ul>\n","</ul> <br>\n","Note: You may get a deprecation warning. Please Ignore it."]},{"metadata":{"scrolled":true,"id":"Kj5AQlFbLtu4","colab_type":"code","colab":{}},"cell_type":"code","source":["sparse_vector2 = sps.csc_matrix((np.array([7.0, 2.0, 1.0, 6.5]), np.array([0, 3, 5, 9]), np.array([0, 4])), shape = (10, 1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E6pJ06uqLtu6","colab_type":"text"},"cell_type":"markdown","source":["Print <b>sparse_vector2</b> and its <b>type</b>"]},{"metadata":{"id":"R1clWVhmLtu6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"b23c1ad0-1361-4af1-dfba-7f33f62dd766","executionInfo":{"status":"ok","timestamp":1552198953474,"user_tz":-660,"elapsed":21139,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print (sparse_vector2)\n","print (type(sparse_vector2))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["  (0, 0)\t7.0\n","  (3, 0)\t2.0\n","  (5, 0)\t1.0\n","  (9, 0)\t6.5\n","<class 'scipy.sparse.csc.csc_matrix'>\n"],"name":"stdout"}]},{"metadata":{"id":"9OUCr_OXLtu8","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"lpoints\"></a>\n","### <span style=\"color:#0b486b\">1.2 Labeled Points</span>\n","\n","So the next data type will be Labeled points. Remember that this data type is mainly used for classification algorithms in supervised learning.<br>\n","\n","Start by importing the following libraries: <br>\n","<ul>\n","    <li>SparseVector from pyspark.mllib.linalg</li>\n","    <li>LabeledPoint from pyspark.mllib.regression</li>\n","</ul>"]},{"metadata":{"id":"7WNcBzIuLtu9","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyspark.mllib.linalg import SparseVector\n","from pyspark.mllib.regression import LabeledPoint"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-zoLOpJxLtvA","colab_type":"text"},"cell_type":"markdown","source":["Remember that with a lableled point, we can create binary or multiclass classification. In this lab, we will deal with binary classification for ease. <br> <br>\n","The <b>LabeledPoint</b> function takes in 2 inputs:\n","<ul>\n","    <li>1st: Label of the Point. In this case (for binary classification), we will be using <font color=\"green\">1.0</font> for <font color=\"green\">positive</font> and <font color=\"red\">0.0</font> for <font color=\"red\">negative</font></li>\n","    <li>2nd: Vector of features for the point (We will input a Dense or Sparse Vector using any of the methods defined in the <b>Dense and Sparse Vectors</b> section of this lab.</b>\n","</ul>"]},{"metadata":{"id":"6tgapsamLtvB","colab_type":"text"},"cell_type":"markdown","source":["Using the LabelPoint class, create a <b>dense</b> feature vector with a <b>positive</b> label called <b>pos_class</b> with the values: <b>5.0, 2.0, 1.0, 9.0</b>"]},{"metadata":{"id":"DNYHl94wLtvB","colab_type":"code","colab":{}},"cell_type":"code","source":["pos_class = LabeledPoint(1.0, [5.0, 2.0, 1.0, 9.0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dzcT8nqtLtvD","colab_type":"text"},"cell_type":"markdown","source":["Print <i>pos_class</i> and its <i>type</i>"]},{"metadata":{"id":"RRadhh0cLtvE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"093ccbb1-cb8b-4fea-b465-4d5154f5a15c","executionInfo":{"status":"ok","timestamp":1552198953480,"user_tz":-660,"elapsed":21141,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(pos_class)\n","type(pos_class)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(1.0,[5.0,2.0,1.0,9.0])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["pyspark.mllib.regression.LabeledPoint"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"bM4Q3-kELtvG","colab_type":"text"},"cell_type":"markdown","source":["Next we will create a <b>sparse</b> feature vector with a <b>negative</b> label called <b>neg_class</b> with the values: <b>1.0, 0.0, 0.0, 4.0, 0.0, 2.0</b>"]},{"metadata":{"id":"7SPDsrF3LtvH","colab_type":"code","colab":{}},"cell_type":"code","source":["neg_class = LabeledPoint(0.0, SparseVector(6, [0, 3, 5], [1.0, 4.0, 2.0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9eI7E5SNLtvK","colab_type":"text"},"cell_type":"markdown","source":["Print <b>neg_class</b> and its <b>type</b>"]},{"metadata":{"id":"rwS-GOxyLtvL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"f3512cac-2037-42b1-a7af-09990860cd93","executionInfo":{"status":"ok","timestamp":1552198953484,"user_tz":-660,"elapsed":21144,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(neg_class)\n","type(neg_class)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(0.0,(6,[0,3,5],[1.0,4.0,2.0]))\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["pyspark.mllib.regression.LabeledPoint"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"fxIOHyJkLtvN","colab_type":"text"},"cell_type":"markdown","source":["---\n","## <span style=\"color:#0b486b\">2. Matrix Data Types</span>\n","\n","\n","In this next section, we will be dealing creating the following matrices:\n","<ul>\n","    <li>Local Matrix</li>\n","    <li>Row Matrix</li>\n","    <li>Indexed Row Matrix</li>\n","    <li>Coordinate Matrix</li>\n","    <li>Block Matrix</li>\n","</ul> \n","\n","Throughout this section, we will be modelling the following matricies: <br> \n","\n","<center>For a Dense Matrix:</center> <br> \n","\n","$$\n"," \\begin{pmatrix}\n","  1.00 & 6.00 & 3.00 & 0.00 \\\\\n","  3.00 & 2.00 & 5.00 & 1.00 \\\\\n","  9.00 & 4.00 & 0.00 & 3.00 \n"," \\end{pmatrix}\n","$$\n","\n","<center>For a Sparse Matrix:</center> <br> \n","\n","$$\n"," \\begin{pmatrix}\n","  1.00 & 0.00 & 3.00 & 0.00 \\\\\n","  3.00 & 0.00 & 0.00 & 1.00 \\\\\n","  0.00 & 4.00 & 0.00 & 0.00 \n"," \\end{pmatrix}\n","$$"]},{"metadata":{"id":"pRH3OxKdLtvN","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"lm\"></a>\n","### <span style=\"color:#0b486b\">2.1 Local Matrix</span>\n","\n","Import the following Library:\n","<ul>\n","    <li>pyspark.mllib.linalg as laMat</li>\n","</ul>"]},{"metadata":{"id":"Y6ZCp5fPLtvO","colab_type":"code","colab":{}},"cell_type":"code","source":["import pyspark.mllib.linalg as laMat"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ooA-s7JkLtvP","colab_type":"text"},"cell_type":"markdown","source":["Create a dense local matrix called <b>dense_LM</b> <br>\n","The inputs into the <b>laMat.Matrices.dense</b> function are:\n","<ul>\n","    <li>1st: Number of Rows</li>\n","    <li>2nd: Number of Columns</li>\n","    <li>3rd: Values in an array format (Read as Column-Major)</li>\n","</ul>"]},{"metadata":{"scrolled":true,"id":"kHPxNCs_LtvP","colab_type":"code","colab":{}},"cell_type":"code","source":["dense_LM = laMat.Matrices.dense(3,4, [1.0, 3.0, 9.0, 6.0, 2.0, 4.0, 3.0, 5.0, 0.0, 0.0, 1.0, 3.0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BaXqAc5XLtvR","colab_type":"text"},"cell_type":"markdown","source":["Print <b>dense_LM</b> and its <b>type</b>"]},{"metadata":{"id":"-IrYNsgbLtvS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"17e0a232-7c39-45c2-ee3a-be9310dcea5d","executionInfo":{"status":"ok","timestamp":1552198953488,"user_tz":-660,"elapsed":21145,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(dense_LM)\n","type(dense_LM)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["DenseMatrix([[1., 6., 3., 0.],\n","             [3., 2., 5., 1.],\n","             [9., 4., 0., 3.]])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["pyspark.mllib.linalg.DenseMatrix"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"qSCT1fI9LtvW","colab_type":"text"},"cell_type":"markdown","source":["Next we will do the same thing with a sparse matrix, calling the output <b>sparse_LM</b>\n","The inputs into the <b>laMat.Matrices.sparse</b> function are:\n","<ul>\n","    <li>1st: Number of Rows</li>\n","    <li>2nd: Number of Columns</li>\n","    <li>3rd: Column Pointers (in a list)</li>\n","    <li>4th: Row Indices (in a list)</li>\n","    <li>5th: Values of the Matrix (in a list)</li>\n","</ul> <br>\n","<b>Note</b>: Remember that this is <b>column-major</b> so all arrays should be read as columns first (top down, left to right)"]},{"metadata":{"id":"6bwOstRmLtvW","colab_type":"code","colab":{}},"cell_type":"code","source":["sparse_LM = laMat.Matrices.sparse(3, 4, [0, 2, 3, 4, 5], [0, 1, 2, 1, 1], [1.0, 3.0, 4.0, 3.0, 1.0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ndyp1vXHLtvY","colab_type":"text"},"cell_type":"markdown","source":["Print <b>sparse_LM</b> and its <b>type</b>"]},{"metadata":{"id":"Bu_X2OxCLtvY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"586afe97-ba62-4269-a5cf-efbd5a40c1ba","executionInfo":{"status":"ok","timestamp":1552198953491,"user_tz":-660,"elapsed":21146,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(sparse_LM)\n","type(sparse_LM)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["3 X 4 CSCMatrix\n","(0,0) 1.0\n","(1,0) 3.0\n","(2,1) 4.0\n","(1,2) 3.0\n","(1,3) 1.0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["pyspark.mllib.linalg.SparseMatrix"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"o0TC5c49Ltva","colab_type":"text"},"cell_type":"markdown","source":["Make sure the output of <b>sparse_LM</b> matches the original matrix."]},{"metadata":{"collapsed":true,"id":"auGeFkoFLtva","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"rm\"></a>\n","### <span style=\"color:#0b486b\">2.2 Row Matrix</span>\n","\n","A RowMatrix is a Row-oriented distributed matrix that doesn't have meaningful row indices.\n","\n","Import the following library:\n","<ul>\n","    <li>RowMatrix from pyspark.mllib.linalg.distributed</li>\n","</ul>"]},{"metadata":{"id":"OAlvgx4ULtvb","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyspark.mllib.linalg.distributed import RowMatrix\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext\n","sc = SparkContext.getOrCreate()\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"3v58xbj4Ltvc","colab_type":"text"},"cell_type":"markdown","source":["Now, let's create a RDD of vectors called <b>rowVecs</b>, using the SparkContext's parallelize function on the <b>Dense Matrix</b>.<br>\n","The input into <b>sc.parallelize</b> is:\n","<ul>\n","    <li>A list (The list we will be creating will be a list of the row values (each row is a list))</li>\n","</ul> <br>\n","<b>Note</b>: And RDD is a fault-tolerated collection of elements that can be operated on in parallel. <br>"]},{"metadata":{"id":"NU9gd8gELtvc","colab_type":"code","colab":{}},"cell_type":"code","source":["rowVecs = sc.parallelize([[1.0, 6.0, 3.0, 0.0],\n","                       [3.0, 2.0, 5.0, 1.0],\n","                       [9.0, 4.0, 0.0, 3.0]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GrEDkMImLtve","colab_type":"text"},"cell_type":"markdown","source":["Next, create a variable called <b>rowMat</b> by using the <b>RowMatrix</b> function and passing in the RDD."]},{"metadata":{"id":"-cu9FWO0Ltvf","colab_type":"code","colab":{}},"cell_type":"code","source":["rowMat = RowMatrix(rowVecs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VlBA51xsLtvg","colab_type":"text"},"cell_type":"markdown","source":["Now we will retrieve the <font color=\"green\">row numbers</font> (save it as <font color=\"green\">m</font>) and <font color=\"blue\">column numbers</font> (save it as <font color=\"blue\">n</font>) from the RowMatrix.\n","<ul>\n","    <li>To get the number of rows, use <i>numRows()</i> on rowMat</li>\n","    <li>To get the number of columns, use <i>numCols()</i> on rowMat</li>\n","</ul>"]},{"metadata":{"id":"_KZ07eSfLtvh","colab_type":"code","colab":{}},"cell_type":"code","source":["m = rowMat.numRows()\n","n = rowMat.numCols()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B08WFgLELtvi","colab_type":"text"},"cell_type":"markdown","source":["Print out <b>m</b> and <b>n</b>. The results should be:\n","<ul>\n","    <li>Number of Rows: 3</li>\n","    <li>Number of Columns: 4</li>\n","</ul>"]},{"metadata":{"id":"Q3rjVcQELtvj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"797b2fa0-8740-4635-ffe1-b0c7bfbc94ab","executionInfo":{"status":"ok","timestamp":1552199857404,"user_tz":-660,"elapsed":3071,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(m)\n","\n","print(n)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["3\n","4\n"],"name":"stdout"}]},{"metadata":{"id":"AHAqheSfLtvk","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"irm\"></a>\n","### <span style=\"color:#0b486b\">2.3 Indexed Row Matrix</span>\n","\n","Since we just created a RowMatrix, which had no meaningful row indicies, let's create an <b>IndexedRowMatrix</b> which has meaningful row indices!\n","\n","Import the following Library:\n","<ul>\n","    <li> IndexedRow, IndexedRowMatrix from pyspark.mllib.linalg.distributed</li>\n","</ul>"]},{"metadata":{"id":"po_80C3MLtvl","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OuGXYDjOLtvm","colab_type":"text"},"cell_type":"markdown","source":["Now, create a RDD called <b>indRows</b> by using the SparkContext's parallelize function on the <b>Dense Matrix</b>. <br>\n","There are two different inputs you can use to create the RDD:\n","<ul>\n","    <li>Method 1: A list containing multiple IndexedRow inputs</li>\n","    <ul>\n","        <li>Input into IndexedRow:</li>\n","        <ul>\n","            <li>1. Index for the given row (row number)</li>\n","            <li>2. row in the matrix for the given index</li>\n","        </ul>\n","        <li>ex. sc.parallelize([IndexedRow(0,[1, 2, 3]), ...])</li>\n","    </ul> <br>\n","    <li>Method 2: A list containing multiple tuples</li>\n","    <ul>\n","        <li>Values in the tuple:</li>\n","        <ul>\n","            <li>1. Index for the given row (row number) (type:long)</li>\n","            <li>2. List containing the values in the row for the given index (type:vector)</li>\n","        </ul>\n","        <li>ex. sc.parallelize([(0, [1, 2, 3]), ...])</li>\n","    </ul>\n","</ul>"]},{"metadata":{"id":"gKQaa96OLtvn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Method 1: Using IndexedRow class\n","indRows = sc.parallelize([IndexedRow(0, [1.0, 6.0, 3.0, 0.0]),\n","                          IndexedRow(1, [3.0, 2.0, 5.0, 1.0]),\n","                          IndexedRow(2, [9.0, 4.0, 0.0, 3.0])])\n","\n","# Method 2: Using (long, vector) tuples\n","indRows = sc.parallelize([(0, [1.0, 6.0, 3.0, 0.0]),\n","                          (1, [3.0, 2.0, 5.0, 1.0]),\n","                          (2, [9.0, 4.0, 0.0, 3.0])])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9tw4Pgc9Ltvp","colab_type":"text"},"cell_type":"markdown","source":["Now, create the <b>IndexedRowMatrix</b> called <b>indRowMat</b> by using the IndexedRowMatrix function and passing in the <b>indRows</b> RDD"]},{"metadata":{"id":"bWqDuijvLtvp","colab_type":"code","colab":{}},"cell_type":"code","source":["indRowMat = IndexedRowMatrix(indRows)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aVfcOq4PLtvr","colab_type":"text"},"cell_type":"markdown","source":["Now we will retrieve the <font color=\"green\">row numbers</font> (save it as <font color=\"green\">m2</font>) and <font color=\"blue\">column numbers</font> (save it as <font color=\"blue\">n2</font>) from the IndexedRowMatrix.\n","<ul>\n","    <li>To get the number of rows, use <i>numRows()</i> on indRowMat</li>\n","    <li>To get the number of columns, use <i>numCols()</i> on indRowMat</li>\n","</ul>"]},{"metadata":{"id":"2fv_pY00Ltvs","colab_type":"code","colab":{}},"cell_type":"code","source":["m2 = indRowMat.numRows()\n","n2 = indRowMat.numCols()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I2AAu2a0Ltvv","colab_type":"text"},"cell_type":"markdown","source":["Print out <b>m2</b> and <b>n2</b>. The results should be:\n","<ul>\n","    <li>Number of Rows: 3</li>\n","    <li>Number of Columns: 4</li>\n","</ul>"]},{"metadata":{"scrolled":true,"id":"w-CyNZPlLtvv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"784cd8b4-ba21-4957-ec62-76b6541fbabb","executionInfo":{"status":"ok","timestamp":1552199861801,"user_tz":-660,"elapsed":7425,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(m2)\n","\n","print(n2)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["3\n","4\n"],"name":"stdout"}]},{"metadata":{"id":"Uf19b7EDLtvw","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"cm\"></a>\n","### <span style=\"color:#0b486b\">2.3 Coordinate Matrix</span>\n","\n","\n","Now it's time to create a different type of matrix, whos use should be when both the dimensions of the matrix is very large, and the data in the matrix is sparse. <br>\n","<b>Note</b>: In this case, we will be using the small, sparse matrix above, just to get the idea of how to initialize a CoordinateMatrix\n","\n","Import the following libraries:\n","<ul>\n","    <li>CoordinateMatrix, MatrixEntry from pyspark.mllib.linalg.distributed</li>\n","</ul>"]},{"metadata":{"id":"SfF4syBhLtvx","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HuwY9ye_Ltvz","colab_type":"text"},"cell_type":"markdown","source":["Now, create a RDD called <b>coordRows</b> by using the SparkContext's parallelize function on the <b>Sparse Matrix</b>. There are two different inputs you can use to create the RDD:\n","<ul>\n","    <li>Method 1: A list containing multiple MatrixEntry inputs</li>\n","    <ul>\n","        <li>Input into MatrixEntry:</li>\n","        <ul>\n","            <li>1. Row index of the matrix (row number) (type: long)</li>\n","            <li>2. Column index of the matrix (column number) (type: long)</li>\n","            <li>3. Value at the (Row Index, Column Index) entry of the matrix (type: float)</li>\n","        </ul>\n","        <li>ex. sc.parallelize([MatrixEntry(0, 0, 1,), ...])</li>\n","    </ul> <br>\n","    <li>Method 2: A list containing multiple tuples</li>\n","    <ul>\n","        <li>Values in the tuple:</li>\n","        <ul>\n","            <li>1. Row index of the matrix (row number) (type: long)</li>\n","            <li>2. Column index of the matrix (column number) (type: long)</li>\n","            <li>3. Value at the (Row Index, Column Index) entry of the matrix (type: float)</li>\n","        </ul>\n","        <li>ex. sc.parallelize([(0, 0, 1), ...])</li>\n","    </ul>\n","</ul>"]},{"metadata":{"id":"21qL_8MJLtv0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Method 1. Using MatrixEntry class\n","coordRows = sc.parallelize([MatrixEntry(0, 0, 1.0),\n","                            MatrixEntry(0, 2, 3.0),\n","                            MatrixEntry(1, 0, 3.0),\n","                            MatrixEntry(1, 3, 1.0),\n","                            MatrixEntry(2, 2, 4.0)])\n","\n","# Method 2. Using (long, long, float) tuples\n","coordRows = sc.parallelize([(0, 0, 1.0),\n","                            (0, 2, 3.0),\n","                            (1, 1, 3.0),\n","                            (1, 3, 1.0), \n","                            (2, 2, 4.0)])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6xsrK-6GLtv1","colab_type":"text"},"cell_type":"markdown","source":["Now, create the <b>CoordinateMatrix</b> called <b>coordMat</b> by using the CoordinateMatrix function and passing in the <b>coordRows</b> RDD"]},{"metadata":{"id":"fSuWdfT2Ltv2","colab_type":"code","colab":{}},"cell_type":"code","source":["coordMat = CoordinateMatrix(coordRows)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ibs1rvwqLtv3","colab_type":"text"},"cell_type":"markdown","source":["Now we will retrieve the <font color=\"green\">row numbers</font> (save it as <font color=\"green\">m3</font>) and <font color=\"blue\">column numbers</font> (save it as <font color=\"blue\">n3</font>) from the CoordinateMatrix.\n","<ul>\n","    <li>To get the number of rows, use <i>numRows()</i> on coordMat</li>\n","    <li>To get the number of columns, use <i>numCols()</i> on coordMat</li>\n","</ul>"]},{"metadata":{"id":"VGsRnQqrLtv4","colab_type":"code","colab":{}},"cell_type":"code","source":["m3 = coordMat.numRows()\n","n3 = coordMat.numCols()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TTLKHZwkLtv7","colab_type":"text"},"cell_type":"markdown","source":["Print out <b>m3</b> and <b>n3</b>. The results should be:\n","<ul>\n","    <li>Number of Rows: 3</li>\n","    <li>Number of Columns: 4</li>\n","</ul>"]},{"metadata":{"scrolled":true,"id":"FbzoGMYvLtv7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"207d7973-a98b-4546-bbe8-9d0e23573c66","executionInfo":{"status":"ok","timestamp":1552199863043,"user_tz":-660,"elapsed":8633,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(m3)\n","\n","print(n3)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["3\n","4\n"],"name":"stdout"}]},{"metadata":{"id":"MANbIKSkLtv8","colab_type":"text"},"cell_type":"markdown","source":["Now, we can get the <b>entries</b> of coordMat by calling the entries method on it. Store this in a variable called coordEnt."]},{"metadata":{"id":"BUS5l9zwLtv9","colab_type":"code","colab":{}},"cell_type":"code","source":["coordEnt = coordMat.entries"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PkTmS5OzLtv-","colab_type":"text"},"cell_type":"markdown","source":["Check out the <i>type</i> of coordEnt."]},{"metadata":{"id":"G3_OVVMGLtv_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b0826e24-f598-4bc9-de63-c32a5128ebd5","executionInfo":{"status":"ok","timestamp":1552199863375,"user_tz":-660,"elapsed":8953,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["type(coordEnt)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.rdd.PipelinedRDD"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"uIKl0SNkLtwA","colab_type":"text"},"cell_type":"markdown","source":["It should be a <b>PipelinedRDD</b> type, which has many methods that are associated with it. One of them is <b>first()</b>, which will get the first element in the RDD. <br> <br>\n","\n","Run coordEnt.first()"]},{"metadata":{"id":"xUEQBDTSLtwA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"9b0cd213-1c03-4706-a832-8ab7f71826a2","executionInfo":{"status":"ok","timestamp":1552199863376,"user_tz":-660,"elapsed":8947,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["coordEnt.first()"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MatrixEntry(0, 0, 1.0)"]},"metadata":{"tags":[]},"execution_count":41}]},{"metadata":{"id":"YpkCdrZpLtwC","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"bm\"></a>\n","### <span style=\"color:#0b486b\">2.4 Block Matrix</span>\n","\n","A BlockMatrix is essentially a matrix consisting of elements which are partitions of the matrix that is being created.\n","\n","Import the following libraries:\n","<ul>\n","    <li>Matrices from pyspark.mllib.linalg</li>\n","    <li>BlockMatrix from pyspark.mllib.linalg.distributed</li>\n","</ul>"]},{"metadata":{"scrolled":true,"id":"rvYIns0lLtwD","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyspark.mllib.linalg import Matrices\n","from pyspark.mllib.linalg.distributed import BlockMatrix"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TsLuI3LxLtwE","colab_type":"text"},"cell_type":"markdown","source":["Now create a <b>RDD</b> of <b>sub-matrix blocks</b>. <br>\n","This will be done using SparkContext's parallelize function. <br>\n","\n","The input into <b>sc.parallelize</b> requires a <b>list of tuples</b>. The tuples are the sub-matrices, which consist of two inputs:\n","<ul>\n","    <li>1st: A tuple containing the row index and column index (row, column), denoting where the sub-matrix will start</li>\n","    <li>2nd: The sub-matrix, which will come from <b>Matrices.dense</b>. The sub-matrix requires 3 inputs:</li>\n","    <ul>\n","        <li>1st: Number of rows</li>\n","        <li>2nd: Number of columns</li>\n","        <li>3rd: A list containing the elements of the sub-matrix. These values are read into the sub-matrix column-major fashion</li>\n","    </ul>\n","</ul> <br>\n","(ex. ((51, 2), Matrices.dense(2, 2, [61.0, 43.0, 1.0, 74.0])) would be one row (one tuple))."]},{"metadata":{"id":"MdRSH_V2LtwF","colab_type":"text"},"cell_type":"markdown","source":["The matrix we will be modelling is <b>Dense Matrix</b> from above. Create the following sub-matrices:\n","<ul>\n","    <li>Row: 0, Column: 0, Values: 1.0, 3.0, 6.0, 2.0, with 2 Rows and 2 Columns </li>\n","    <li>Row: 2, Column: 0, Values: 9.0, 4.0, with 1 Row and 2 Columns</li>\n","    <li>Row: 0, Column: 2, Values: 3.0, 5.0, 0.0, 0.0, 1.0, 3.0, with 3 Rows and 2 Columns</li>\n","</ul>"]},{"metadata":{"id":"dAw16uYtLtwG","colab_type":"code","colab":{}},"cell_type":"code","source":["blocks = sc.parallelize([((0, 0), Matrices.dense(2, 2, [1.0, 3.0, 6.0, 2.0])), \n","                         ((2, 0), Matrices.dense(1, 2, [9.0, 4.0])), \n","                         ((0, 2), Matrices.dense(3, 2, [3.0, 5.0, 0.0, 0.0, 1.0, 3.0]))])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AdmDmQQlLtwH","colab_type":"text"},"cell_type":"markdown","source":["Now that we have the RDD, it's time to create the BlockMatrix called <b>blockMat</b> using the BlockMatrix class. The <b>BlockMatrix</b> class requires 3 inputs:\n","<ul>\n","    <li>1st: The RDD of sub-matricies</li>\n","    <li>2nd: The rows per block. Keep this value at 1</li>\n","    <li>3rd: The columns per block. Keep this value at 1</li>\n","</ul>"]},{"metadata":{"id":"dwBp4ZXOLtwH","colab_type":"code","colab":{}},"cell_type":"code","source":["blockMat = BlockMatrix(blocks, 1, 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OGOstI_PLtwL","colab_type":"text"},"cell_type":"markdown","source":["Now we will retrieve the <font color=\"green\">row numbers</font> (save it as <font color=\"green\">m4</font>) and <font color=\"blue\">column numbers</font> (save it as <font color=\"blue\">n4</font>) from the BlockMatrix.\n","<ul>\n","    <li>To get the number of rows, use <i>numRows()</i> on blockMat</li>\n","    <li>To get the number of columns, use <i>numCols()</i> on blockMat</li>\n","</ul>"]},{"metadata":{"scrolled":true,"id":"upwe2QUTLtwL","colab_type":"code","colab":{}},"cell_type":"code","source":["m4 = blockMat.numRows()\n","n4 = blockMat.numCols()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xzRDmNXcLtwN","colab_type":"text"},"cell_type":"markdown","source":["Print out <b>m4</b> and <b>n4</b>. The results should be:\n","<ul>\n","    <li>Number of Rows: 3</li>\n","    <li>Number of Columns: 4</li>\n","</ul>"]},{"metadata":{"id":"jtvVPHPMLtwN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"ad83ca54-e921-453b-f2d7-d54d63b5e608","executionInfo":{"status":"ok","timestamp":1552199864721,"user_tz":-660,"elapsed":10261,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(m4)\n","\n","print(n4)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["3\n","4\n"],"name":"stdout"}]},{"metadata":{"id":"010_x_4HLtwO","colab_type":"text"},"cell_type":"markdown","source":["Now, we need to check if our matrix is correct. We can do this by first converting <b>blockMat</b> into a LocalMatrix, by using the <b>.toLocalMatrix()</b> function on our matrix. Store the result into a variable called <b>locBMat</b>"]},{"metadata":{"id":"7T-s3p7rLtwP","colab_type":"code","colab":{}},"cell_type":"code","source":["locBMat = blockMat.toLocalMatrix()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YXlO4_9wLtwQ","colab_type":"text"},"cell_type":"markdown","source":["Now print out <b>locBMat</b> and its <b>type</b>. The result should model the original <b>Dense Matrix</b> and the type should be a DenseMatrix."]},{"metadata":{"id":"kXH07bVALtwS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"ebd909ca-69b5-47fb-c71f-16fc3bc82dc2","executionInfo":{"status":"ok","timestamp":1552199864724,"user_tz":-660,"elapsed":10255,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["print(locBMat)\n","print(type(locBMat))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["DenseMatrix([[1., 6., 3., 0.],\n","             [3., 2., 5., 1.],\n","             [9., 4., 0., 3.]])\n","<class 'pyspark.mllib.linalg.DenseMatrix'>\n"],"name":"stdout"}]},{"metadata":{"id":"uEM9zWdXLtwT","colab_type":"text"},"cell_type":"markdown","source":["---\n","## <span style=\"color:#0b486b\">3. Matrix Conversions</span>\n","\n","\n","In this bonus section, we will talk about a relationship between the different types of matrices. You can convert between these matrices that we discussed with the following functions. <br>\n","<ul>\n","    <li>.toRowMatrix() converts the matrix to a RowMatrix</li>\n","    <li>.toIndexedRowMatrix() converts the matrix to an IndexedRowMatrix</li>\n","    <li>.toCoordinateMatrix() converts the matrix to a CoordinateMatrix</li>\n","    <li>.toBlockMatrix() converts the matrix to a BlockMatrix</li>\n","</ul>"]},{"metadata":{"id":"BW_z4pUYLtwT","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"irmc\"></a>\n","### <span style=\"color:#0b486b\">3.1  Indexed Row Matrix Conversions</span>\n","\n","The following conversions are supported for an IndexedRowMatrix:\n","<ul>\n","    <li>IndexedRowMatrix -> RowMatrix</li>\n","    <li>IndexedRowMatrix -> CoordinateMatrix</li>\n","    <li>IndexedRowMatrix -> BlockMatrix</li>\n","</ul>"]},{"metadata":{"scrolled":false,"id":"6fA6spiGLtwV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"2f8608f2-7f89-4428-8203-c5fc01543c93","executionInfo":{"status":"ok","timestamp":1552199864725,"user_tz":-660,"elapsed":10251,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["# Convert to a RowMatrix\n","rMat = indRowMat.toRowMatrix()\n","print(type(rMat))\n","\n","# Convert to a CoordinateMatrix\n","cMat = indRowMat.toCoordinateMatrix()\n","print(type(cMat))\n","\n","# Convert to a BlockMatrix\n","bMat = indRowMat.toBlockMatrix()\n","print(type(bMat))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["<class 'pyspark.mllib.linalg.distributed.RowMatrix'>\n","<class 'pyspark.mllib.linalg.distributed.CoordinateMatrix'>\n","<class 'pyspark.mllib.linalg.distributed.BlockMatrix'>\n"],"name":"stdout"}]},{"metadata":{"id":"nAiWbc4yLtwW","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"cmc\"></a>\n","### <span style=\"color:#0b486b\">3.2  Coordinate Matrix Conversions</span>\n","\n","The following conversions are supported for an CoordinateMatrix:\n","<ul>\n","    <li>CoordinateMatrix -> RowMatrix</li>\n","    <li>CoordinateMatrix -> IndexedRowMatrix</li>\n","    <li>CoordinateMatrix -> BlockMatrix</li>\n","</ul>"]},{"metadata":{"scrolled":true,"id":"SmfKNn9uLtwX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"a33f473b-4121-4167-e8d8-12062c4131e2","executionInfo":{"status":"ok","timestamp":1552199865051,"user_tz":-660,"elapsed":10570,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["# Convert to a RowMatrix\n","rMat2 = coordMat.toRowMatrix()\n","print(type(rMat2))\n","\n","# Convert to an IndexedRowMatrix\n","iRMat = coordMat.toIndexedRowMatrix()\n","print(type(iRMat))\n","\n","# Convert to a BlockMatrix\n","bMat2 = coordMat.toBlockMatrix()\n","print(type(bMat2))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["<class 'pyspark.mllib.linalg.distributed.RowMatrix'>\n","<class 'pyspark.mllib.linalg.distributed.IndexedRowMatrix'>\n","<class 'pyspark.mllib.linalg.distributed.BlockMatrix'>\n"],"name":"stdout"}]},{"metadata":{"id":"m81USk1uLtwY","colab_type":"text"},"cell_type":"markdown","source":["<a id = \"bmc\"></a>\n","### <span style=\"color:#0b486b\">3.3  Block Matrix Conversions</span>\n","\n","\n","The following conversions are supported for an BlockMatrix:\n","<ul>\n","    <li>BlockMatrix -> LocalMatrix (Can display the Matrix)</li>\n","    <li>BlockMatrix -> IndexedRowMatrix</li>\n","    <li>BlockMatrix -> CoordinateMatrix</li>\n","</ul>"]},{"metadata":{"id":"UomLrvNdLtwY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"83d32940-8114-4352-f58f-562fe6f35e34","executionInfo":{"status":"ok","timestamp":1552199865052,"user_tz":-660,"elapsed":10566,"user":{"displayName":"Yale","photoUrl":"https://lh4.googleusercontent.com/-5_QILC8qmus/AAAAAAAAAAI/AAAAAAAAAmw/SHwGbrUo4gU/s64/photo.jpg","userId":"04458048662130211781"}}},"cell_type":"code","source":["# Convert to a LocalMatrix\n","lMat = blockMat.toLocalMatrix()\n","print(type(lMat))\n","\n","# Convert to an IndexedRowMatrix\n","iRMat2 = blockMat.toIndexedRowMatrix()\n","print(type(iRMat2))\n","\n","# Convert to a CoordinateMatrix\n","cMat2 = blockMat.toCoordinateMatrix()\n","print(type(cMat2))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["<class 'pyspark.mllib.linalg.DenseMatrix'>\n","<class 'pyspark.mllib.linalg.distributed.IndexedRowMatrix'>\n","<class 'pyspark.mllib.linalg.distributed.CoordinateMatrix'>\n"],"name":"stdout"}]}]}